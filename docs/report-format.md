# Report Format Documentation

This document describes the structure and format of reports generated by the discovery pipeline.

## Report Output Location

All reports are written to `docs/REPORTS/<timestamp>/` where `<timestamp>` is an ISO 8601 timestamp with colons and periods replaced by hyphens.

Example: `docs/REPORTS/2026-01-27T15-20-10-000Z/`

## Files Generated

Each run creates three files:

1. `run.json` - Machine-readable structured report
2. `summary.md` - Human-readable summary
3. `logs.json` - Complete log entries from the run

## run.json Structure

```json
{
  "startTime": "2026-01-27T15:20:10.000Z",
  "endTime": "2026-01-27T15:22:45.123Z",
  "duration": 155123,
  "command": "discover --baseUrl https://example.com",
  "config": {
    "baseUrl": "https://example.com",
    "outDir": "crawler/output",
    "respectRobots": true,
    "maxDepth": 2,
    "maxPages": 500
  },
  "stats": {
    "pagesFound": 42,
    "pagesIncluded": 40,
    "excludedExternal": 10,
    "excludedDuplicates": 5,
    "excludedByRules": 7
  },
  "warnings": [
    "Blocked by robots.txt: https://example.com/admin",
    "Failed to check status for https://example.com/page: Network error"
  ],
  "errors": [],
  "outputs": {
    "manifest": "crawler/output/manifest.json",
    "report": "docs/REPORTS/2026-01-27T15-20-10-000Z"
  }
}
```

### Fields

- **startTime** (string): ISO 8601 timestamp when the run started
- **endTime** (string): ISO 8601 timestamp when the run completed
- **duration** (number): Duration in milliseconds
- **command** (string): The command that was executed
- **config** (object): Configuration options used for the run
- **stats** (object): Statistics about the discovery process
  - **pagesFound** (number): Total pages discovered from all sources
  - **pagesIncluded** (number): Pages included in the final manifest
  - **excludedExternal** (number): External URLs that were filtered out
  - **excludedDuplicates** (number): Duplicate URLs that were filtered out
  - **excludedByRules** (number): URLs excluded by filtering rules
- **warnings** (array): List of warning messages from the run
- **errors** (array): List of error messages from the run
- **outputs** (object): Paths to output files
  - **manifest** (string): Path to the generated manifest.json
  - **report** (string): Path to the report directory

## summary.md Structure

The summary.md file provides a human-readable overview of the run:

```markdown
# Discovery Run Summary

## Run Information

- **Command**: `discover --baseUrl https://example.com`
- **Start Time**: 2026-01-27T15:20:10.000Z
- **End Time**: 2026-01-27T15:22:45.123Z
- **Duration**: 155.12s

## Statistics

- **Pages Found**: 42
- **Pages Included**: 40
- **Excluded (External)**: 10
- **Excluded (Duplicates)**: 5
- **Excluded (By Rules)**: 7

## Outputs

- **Manifest**: `crawler/output/manifest.json`
- **Report**: `docs/REPORTS/2026-01-27T15-20-10-000Z`

## Status

✅ **Completed successfully**

## Warnings (2)

- Blocked by robots.txt: https://example.com/admin
- Failed to check status for https://example.com/page: Network error
```

### Status Icons

- ✅ Completed successfully (no errors or warnings)
- ⚠️ Completed with warnings (warnings but no errors)
- ❌ Completed with errors (one or more errors)

## logs.json Structure

The logs.json file contains all log entries from the run:

```json
[
  {
    "timestamp": "2026-01-27T15:20:10.000Z",
    "level": "INFO",
    "message": "Starting discovery",
    "data": {}
  },
  {
    "timestamp": "2026-01-27T15:20:11.123Z",
    "level": "DEBUG",
    "message": "Trying sitemap: https://example.com/sitemap.xml"
  },
  {
    "timestamp": "2026-01-27T15:20:12.456Z",
    "level": "WARN",
    "message": "Blocked by robots.txt: https://example.com/admin"
  }
]
```

### Log Levels

- **ERROR**: Critical failures that prevent completion
- **WARN**: Potential issues that don't prevent completion
- **INFO**: Normal operational messages
- **DEBUG**: Detailed diagnostic information

## Usage

These reports can be used for:

1. **Debugging** - Review logs to understand what happened during discovery
2. **Auditing** - Track what URLs were discovered and why some were excluded
3. **Automation** - Parse run.json programmatically to integrate with other tools
4. **Documentation** - Include summary.md in documentation or reports

## Example Integration

```bash
# Run discovery and capture report path
npm run discover -- --baseUrl https://example.com

# Find latest report
LATEST_REPORT=$(ls -t docs/REPORTS | head -1)

# Parse stats
cat "docs/REPORTS/$LATEST_REPORT/run.json" | jq '.stats'

# Read summary
cat "docs/REPORTS/$LATEST_REPORT/summary.md"
```
